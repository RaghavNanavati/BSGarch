# -*- coding: utf-8 -*-
"""BSGARCH.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17DIq86VdmFcSAvfI2M5POy3AvoVU9i9F
"""

!pip install yfinance arch pandas numpy matplotlib scipy

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from arch import arch_model
from datetime import datetime
from math import exp, log, sqrt
from scipy.stats import norm

# ─── PART A: GARCH(1,1) VOL FORECAST ────────────────────────────────────

ticker     = "AAPL"
start_date = "2020-01-01"
end_date   = datetime.today().strftime("%Y-%m-%d")

# 1. Download price data & compute log‑returns
df = yf.download(ticker, start=start_date, end=end_date)
df["LogRet"] = np.log(df["Close"] / df["Close"].shift(1))
rets = df["LogRet"].dropna()

# 2. Fit GARCH(1,1)
model = arch_model(rets, mean="Constant", vol="Garch", p=1, q=1, dist="normal")
res   = model.fit(disp="off")
print(res.summary())

# 3. Forecast 30 days ahead
horizon = 30
fcast   = res.forecast(horizon=horizon).variance.values[-1,:]
daily_vol = np.sqrt(fcast)
ann_vol   = daily_vol * np.sqrt(252)

vol_df = pd.DataFrame({
    "Day": np.arange(1, horizon+1),
    "Daily_Stdev": daily_vol,
    "Annualized_Stdev": ann_vol
}).round(4)

print("\n30‑Day GARCH Forecast (first 10 days):")
print(vol_df.head(10))

plt.figure(figsize=(10,5))
plt.plot(vol_df["Day"], vol_df["Annualized_Stdev"], marker="o")
plt.title(f"{ticker}: 30‑Day GARCH(1,1) Annualized Vol Forecast")
plt.xlabel("Days Ahead"); plt.ylabel("Annualized Volatility")
plt.grid(True)
plt.show()


# ─── PART B: AMERICAN PRICER + ANALYTIC GREEKS ──────────────────────────

# 1. CRR binomial tree for American option price
def binomial_american(S, K, T, r, sigma, steps, option_type="call", q=0.0):
    dt   = T/steps
    u    = exp(sigma * sqrt(dt))
    d    = 1/u
    pu   = (exp((r - q)*dt) - d)/(u - d)
    pd   = 1 - pu
    disc = exp(-r*dt)

    # Terminal payoffs
    ST = S * (u**np.arange(steps, -1, -1)) * (d**np.arange(0, steps+1))
    if option_type=="call":
        vals = np.maximum(ST - K, 0)
    else:
        vals = np.maximum(K - ST, 0)

    # Backward induction
    for i in range(steps-1, -1, -1):
        vals = disc*(pu*vals[1:] + pd*vals[:-1])
        ST   = S * (u**np.arange(i, -1, -1)) * (d**np.arange(0, i+1))
        if option_type=="call":
            vals = np.maximum(vals, ST - K)
        else:
            vals = np.maximum(vals, K - ST)
    return vals[0]

# 2. Analytic Black–Scholes–Merton Greeks with continuous dividend yield q
def bs_greeks(S, K, T, r, q, sigma, opt="call"):
    d1 = (log(S/K) + (r - q + 0.5*sigma**2)*T) / (sigma*sqrt(T))
    d2 = d1 - sigma*sqrt(T)
    pdf = norm.pdf(d1)
    cdf = norm.cdf
    if opt=="call":
        delta = exp(-q*T)*cdf(d1)
        theta = (
            -S*sigma*exp(-q*T)*pdf/(2*sqrt(T))
            + q*S*exp(-q*T)*cdf(d1)
            - r*K*exp(-r*T)*cdf(d2)
        )/365
        rho   =  K*T*exp(-r*T)*cdf(d2)/100
    else:
        delta = exp(-q*T)*(cdf(d1)-1)
        theta = (
            -S*sigma*exp(-q*T)*pdf/(2*sqrt(T))
            - q*S*exp(-q*T)*cdf(-d1)
            + r*K*exp(-r*T)*cdf(-d2)
        )/365
        rho   = -K*T*exp(-r*T)*cdf(-d2)/100

    gamma = exp(-q*T)*pdf/(S*sigma*sqrt(T))
    vega  = S*exp(-q*T)*pdf*sqrt(T)/100
    return delta, gamma, vega, theta, rho

# 3. Pull stock & option‐chain data
stk = yf.Ticker(ticker)
S   = stk.history(period="1d")["Close"][-1]
q   = stk.info.get("dividendYield", 0.0) or 0.0
r   = 0.05
exp_str = stk.options[2]
exp_dt  = datetime.strptime(exp_str, "%Y-%m-%d")
T       = (exp_dt - datetime.today()).days/365.0

chain = stk.option_chain(exp_str)
steps = 500

# 4. Loop through calls & puts
results = []
for df_opt, typ in [(chain.calls, "call"), (chain.puts, "put")]:
    for _, row in df_opt.iterrows():
        K     = row["strike"]
        sigma = row["impliedVolatility"]
        price = binomial_american(S, K, T, r, sigma, steps, typ, q)
        de, ga, ve, th, rh = bs_greeks(S, K, T, r, q, sigma, typ)
        results.append({
            "type": typ,
            "strike": K,
            "implied_vol": sigma,
            "price": price,
            "delta": de,
            "gamma": ga,
            "vega": ve,
            "theta": th,
            "rho": rh
        })

df_greeks = pd.DataFrame(results).round(6)
pd.set_option("display.float_format", "{:.6f}".format)
print(df_greeks.head(10))

checks = []
for _, row in df_greeks.iterrows():
    opt   = row["type"]
    K     = row["strike"]
    sigma = row["implied_vol"]
    price = row["price"]
    delta = row["delta"]
    gamma = row["gamma"]
    vega  = row["vega"]
    theta = row["theta"]
    rho   = row["rho"]

    # Analytical Greeks for cross‑check
    delta_bs, gamma_bs, *_ = bs_greeks(S, K, T, r, q, sigma, opt)

    # No‑arbitrage price bounds
    if opt == "call":
        lower, upper = max(S - K, 0), S
    else:
        lower = max(K - S, 0)
        upper = K * exp(-r * T)
    price_ok = lower <= price <= upper

    # Sign & range checks
    delta_ok = (0 <= delta <= 1) if opt == "call" else (-1 <= delta <= 0)
    gamma_ok = gamma >= 0
    vega_ok  = vega  >= 0
    theta_ok = theta <= 0
    rho_ok   = (rho >= 0) if opt == "call" else (rho <= 0)

    # Relative errors vs. analytic
    rel_err = lambda x,y: abs(x - y) / max(abs(y), 1e-6)
    delta_err = rel_err(delta, delta_bs)
    gamma_err = rel_err(gamma, gamma_bs)

    checks.append({
        **row.to_dict(),
        "price_ok": price_ok,
        "delta_ok": delta_ok,
        "gamma_ok": gamma_ok,
        "vega_ok": vega_ok,
        "theta_ok": theta_ok,
        "rho_ok": rho_ok,
        "delta_err": delta_err,
        "gamma_err": gamma_err
    })

check_df = pd.DataFrame(checks)

# Summarize failures
print("\nValidation failures:")
for col in ["price_ok","delta_ok","gamma_ok","vega_ok","theta_ok","rho_ok"]:
    print(f"  {col}: {(~check_df[col]).sum()} / {len(check_df)}")

print(f"\nMean relative Δ error: {check_df['delta_err'].mean():.6f}")
print(f"Mean relative Γ error: {check_df['gamma_err'].mean():.6f}")

# ─── PART C: COMPARE IMPLIED VOL vs. GARCH FORECAST ────────────────────

# 1. Compute days to expiry in trading days (≈252 trading days/year)
days_to_exp = int(round(T * 252))

# 2. Cap at your max GARCH horizon
max_day = vol_df["Day"].max()
forecast_day = min(days_to_exp, max_day)

# 3. Pull the matching GARCH forecast
forecast_vol = vol_df.loc[vol_df["Day"] == forecast_day, "Annualized_Stdev"].iloc[0]
print(f"Using GARCH forecast for Day {forecast_day} → annualized vol = {forecast_vol:.4f}")

# 4. Merge into your Greeks table
df_analysis = df_greeks.copy()
df_analysis["forecast_vol"] = forecast_vol

# 5. Compute vol spread & flags
df_analysis["vol_diff"]      = df_analysis["implied_vol"] - df_analysis["forecast_vol"]
df_analysis["cheap_vol"]     = df_analysis["vol_diff"] < 0    # implied < forecast
df_analysis["expensive_vol"] = df_analysis["vol_diff"] > 0    # implied > forecast

# 6. Rank cheap options by vega (highest sensitivity to vol)
cheap = df_analysis[df_analysis["cheap_vol"]].sort_values("vega", ascending=False)
expensive = df_analysis[df_analysis["expensive_vol"]].sort_values("vol_diff", ascending=False)

# 7. Show top candidates
print("\nTop 5 ‘cheap vol’ options (buy candidates):")
print(cheap.to_string(index=False))

print("\nTop 5 ‘expensive vol’ options (sell candidates):")
print(expensive.to_string(index=False))

import numpy as np
import matplotlib.pyplot as plt

# 1. Pull market quotes into a single DataFrame
calls = chain.calls.copy()
calls["type"] = "call"
puts  = chain.puts.copy()
puts["type"]  = "put"

market = pd.concat([calls, puts], ignore_index=True)[
    ["type", "strike", "lastPrice", "bid", "ask"]
].rename(columns={"lastPrice": "last_price"})
# compute mid‐price as (bid+ask)/2
market["mid_price"] = (market["bid"] + market["ask"]) / 2

# 2. Merge market quotes with your theoretical prices & Greeks
df_compare = df_greeks.merge(
    market,
    on=["type", "strike"],
    how="inner"
)

# 3. Compute pricing errors vs. last trade and vs. mid price
df_compare["err_last"]     = df_compare["price"] - df_compare["last_price"]
df_compare["err_mid"]      = df_compare["price"] - df_compare["mid_price"]
df_compare["rel_err_last"] = df_compare["err_last"]  / df_compare["last_price"]
df_compare["rel_err_mid"]  = df_compare["err_mid"]   / df_compare["mid_price"]

# 4. Summary statistics for your pricing errors
mae_mid  = df_compare["err_mid"].abs().mean()
rmse_mid = np.sqrt((df_compare["err_mid"]**2).mean())

print(f"Mean Absolute Error vs. Mid Price: {mae_mid:.4f}")
print(f"RMSE vs. Mid Price:                {rmse_mid:.4f}")

# 5. Diagnostics plots

# 5a. Scatter plot: model price vs. market mid price
plt.figure(figsize=(6,6))
plt.scatter(df_compare["mid_price"], df_compare["price"], alpha=0.5)
minp = df_compare[["mid_price","price"]].min().min()
maxp = df_compare[["mid_price","price"]].max().max()
plt.plot([minp, maxp], [minp, maxp], "r--", label="45° line")
plt.xlabel("Market Mid Price")
plt.ylabel("Model Price")
plt.title("Model vs. Market Mid Price")
plt.legend()
plt.grid(True)
plt.show()

# 5b. Histogram of pricing errors (model – mid)
plt.figure(figsize=(6,4))
plt.hist(df_compare["err_mid"], bins=50, edgecolor="k")
plt.xlabel("Model Price − Market Mid Price")
plt.title("Distribution of Pricing Errors")
plt.grid(True)
plt.show()

# 6. Flag significant mispricings
threshold = 0.10  # dollar threshold
mis = df_compare[np.abs(df_compare["err_mid"]) > threshold]

print("\nOptions with |Model − Mid| > $0.10:")
print(mis[["type","strike","price","mid_price","err_mid","rel_err_mid"]]
      .sort_values("err_mid", key=lambda x: x.abs(), ascending=False)
      .to_string(index=False))

# ─────────────────────────────────────────────────────────────────────────────
# PART 5: AUTOMATIC THRESHOLD SELECTION FOR MISPRICING & VOL DIFF
# (continuation: uses df_compare and df_analysis)
# ─────────────────────────────────────────────────────────────────────────────

# 1. Pricing‐error distribution
err_mid_abs = df_compare["err_mid"].abs()
mean_err    = err_mid_abs.mean()
std_err     = err_mid_abs.std()
p90_err     = err_mid_abs.quantile(0.90)   # 90th percentile

print("Pricing‐error stats (abs):")
print(f" • Mean   = {mean_err:.4f}")
print(f" • 1σ     = {std_err:.4f}")
print(f" • 90%ile = {p90_err:.4f}")

# Choose threshold: e.g. 90th‐percentile absolute error
pricing_threshold = p90_err

# 2. Vol_diff distribution
vol_diff_abs = df_analysis["vol_diff"].abs()
mean_vd      = vol_diff_abs.mean()
std_vd       = vol_diff_abs.std()
p90_vd       = vol_diff_abs.quantile(0.90)

print("\nVol_diff stats (abs):")
print(f" • Mean   = {mean_vd:.4f}")
print(f" • 1σ     = {std_vd:.4f}")
print(f" • 90%ile = {p90_vd:.4f}")

# Choose threshold: e.g. 90th‐percentile vol_diff
vol_threshold = p90_vd

print(f"\n→ Set pricing_error threshold = ±{pricing_threshold:.4f}")
print(f"→ Set vol_diff threshold      = ±{vol_threshold:.4f}")

# 3. Re‐flag significant mispricings & vol signals
df_compare["signal_price_mis"] = df_compare["err_mid"].abs() > pricing_threshold
df_analysis["signal_vol_mis"]  = df_analysis["vol_diff"].abs() > vol_threshold

# 4. Show examples
print("\nOptions with |pricing_error| > threshold:")
print(df_compare[df_compare["signal_price_mis"]]
      [["type","strike","price","mid_price","err_mid","rel_err_mid"]]
      .sort_values("err_mid", key=lambda x: x.abs(), ascending=False))

print("\nOptions with |vol_diff| > threshold:")
print(df_analysis[df_analysis["signal_vol_mis"]]
      [["type","strike","implied_vol","forecast_vol","vol_diff"]]
      .sort_values("vol_diff", key=lambda x: x.abs(), ascending=False))